# Transformer

## Transformer introduction: 
- Transformer itself on pytorch: https://docs.google.com/presentation/d/1uDqKkrXPaOFeKrQXSwY7KXhvx2aVZ07x3pVVM4OVfH8/edit#slide=id.g31d09b857a6_0_55
- How to train a Transformer for machine translation: https://docs.google.com/presentation/d/1XLpuKlBQSuXCXQS1cbYu4S7LsuWVqzutIMuD2mAaEsU/edit#slide=id.g31d00a118d9_0_81

## Transformer visualization: 
https://github.com/Apollo1840/transformer/blob/main/visual_model_attn.py

- A straightforward heatmap for global overview.
- Detailed line-based plots to understand token-to-token interactions.
- Extended multi-head visualizations to compare contributions across different attention heads, with focusing on
certain token, man can observe different aspectives of heads.

## Transformer variants: 
https://www.notion.so/Transformer-variants-1605e815919080acb611faed9de730fa?pvs=4