# DALL-E 2
reference: https://openai.com/index/dall-e-2/

DALL-E 2 is a text-guided image generator.

## Procedure

The text is encoded as a text embedding, 
this embedding is transformed into an image embedding to guide the de-noising process of a low resolution noise image.
Afterwards, the low resolution image is upsampled into a high resolution image.

```bash

text embedding -> image embedding -> image generation with denoising -> upsampling

```

Details:
- The text embedding is generated by a already aligned text encoder such as **CLIP**.
- The text embedding is **transformed** into image embedding by another(independent) diffusion model or by an auto-regressive model.
- The image generation is a standard **diffusion** process with cross-attention from the transformed text embedding.
- When in the text-guided mode, the image generation is not fully controlled by prompt. It is controlled via a coefficient called **Guidance Scale**.
- The **upsampler** is independent of the whole process.

## Comments

Following research like stable diffusion proved that the transformation from text embedding to image embedding is not necessary.
