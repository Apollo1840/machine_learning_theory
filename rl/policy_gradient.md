# Policy Gradient

The policy is represented as $ğœ‹_ğœƒ(a \mid s)$, which is the probability of taking action $a$ in state $s$, parameterized by $ğœƒ$ (weights of a neural network, for instance).


